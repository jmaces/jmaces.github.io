@unpublished{waldchen_computational_2019,
 abstract = {For a Boolean function \$\Phi\colon\{0,1\}^d\to\{0,1\}\$ and an assignment to its variables \$\mathbf{x}=(x_1, x_2, \dots, x_d)\$ we consider the problem of finding the subsets of the variables that are sufficient to determine the function value with a given probability \$\delta\$. This is motivated by the task of interpreting predictions of binary classifiers described as Boolean circuits (which can be seen as special cases of neural networks). We show that the problem of deciding whether such subsets of relevant variables of limited size \$k\leq d\$ exist is complete for the complexity class \$\mathsf{NP}^\mathsf{PP}\$ and thus generally unfeasible to solve. We introduce a variant where it suffices to check whether a subset determines the function value with probability at least \$\delta\$ or at most \$\delta-\gamma\$ for \$0<\gamma<\delta\$. This reduces the complexity to the class \$\mathsf{NP}^\mathsf{BPP}\$. Finally, we show that finding the minimal set of relevant variables can not be reasonably approximated, i.e. with an approximation factor \$d^{1-\alpha}\$ for \$\alpha>0\$, by a polynomial time algorithm unless \$\mathsf{P}=\mathsf{NP}\$ (this holds even with the probability gap).},
 author = {W{\"a}ldchen, Stephan and Macdonald, Jan and Hauch, Sascha and Kutyniok, Gitta},
 keywords = {Complexity Theory, Explainable Neural Networks},
 month = {June},
 note = {arXiv: 1905.09163},
 title = {The Computational Complexity of Understanding Network Decisions},
 url = {http://arxiv.org/abs/1905.09163},
 year = {2019}
}
